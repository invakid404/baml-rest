syntax = "proto3";

package workerplugin;

option go_package = "github.com/invakid404/baml-rest/workerplugin";

// Request to call a BAML method
message CallRequest {
  string method_name = 1;
  bytes input_json = 2;        // JSON-encoded input struct (includes __baml_options__ if present)
  bool enable_raw_collection = 3;  // When true, capture raw LLM response via OnTick/SSE parsing
}

// Streaming result
message StreamResult {
  enum Kind {
    STREAM = 0;
    FINAL = 1;
    ERROR = 2;
    HEARTBEAT = 3;  // Signals first byte received from LLM (filtered at pool level)
  }
  Kind kind = 1;
  bytes data_json = 2;         // JSON-encoded stream/final data
  string raw = 3;              // Raw LLM response text (populated on FINAL)
  string error = 4;            // Error message (populated on ERROR)
  string stacktrace = 5;       // Stacktrace (populated on ERROR, when available)
}

// Health check
message Empty {}

message HealthResponse {
  bool healthy = 1;
}

// Metrics response - contains serialized Prometheus metrics
message MetricsResponse {
  // Serialized prometheus MetricFamily protos
  // Use prometheus client_model to deserialize
  repeated bytes metric_families = 1;
}

// GC response - contains memory stats before/after GC
message GCResponse {
  uint64 heap_alloc_before = 1;
  uint64 heap_alloc_after = 2;
  uint64 heap_released = 3;
}

// Worker service
service Worker {
  // Streaming call - returns stream of results
  // Used for both streaming and non-streaming calls
  rpc CallStream(CallRequest) returns (stream StreamResult);

  // Health check
  rpc Health(Empty) returns (HealthResponse);

  // Get Prometheus metrics from worker process
  rpc GetMetrics(Empty) returns (MetricsResponse);

  // Trigger garbage collection and release memory to OS
  rpc TriggerGC(Empty) returns (GCResponse);
}
