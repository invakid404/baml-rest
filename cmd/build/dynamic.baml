// DO NOT MODIFY - Auto-generated by baml-rest
// This file provides the dynamic prompt functionality

class Baml_Rest_CacheControl {
  cache_type string @alias("type")  // "ephemeral" - aliased because 'type' is reserved
}

class Baml_Rest_MessageMetadata {
  cache_control Baml_Rest_CacheControl?  // Anthropic prompt caching
  // Future metadata fields go here
}

class Baml_Rest_Message {
  role string
  content string
  metadata Baml_Rest_MessageMetadata?
}

class Baml_Rest_DynamicOutput {
  @@dynamic
}

// Placeholder client - callers MUST provide client_registry.primary
// For cache_control to work, include allowed_role_metadata in client options
client<llm> Baml_Rest_DynamicClient {
  provider "openai"
  options {
    model "gpt-4o-mini"
  }
}

function Baml_Rest_Dynamic(messages: Baml_Rest_Message[]) -> Baml_Rest_DynamicOutput {
  client Baml_Rest_DynamicClient
  prompt #"
    {% for m in messages %}
      {% if m.metadata and m.metadata.cache_control %}
        {{ _.role(m.role, cache_control=m.metadata.cache_control) }}
      {% else %}
        {{ _.role(m.role) }}
      {% endif %}
      {{ m.content | replace("{output_format}", ctx.output_format) }}
    {% endfor %}
  "#
}
